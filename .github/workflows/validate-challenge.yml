name: üéØ Challenge Validation

on:
  pull_request:
    branches: [ main, develop ]
    paths: 
      - 'challenges/**'
  push:
    branches: [ main ]
    paths:
      - 'challenges/**'
  workflow_dispatch:
    inputs:
      challenge_path:
        description: 'Spezifischer Challenge-Pfad zum Testen'
        required: false
        default: ''

env:
  NODE_VERSION: '18'
  DOTNET_VERSION: '8.0.x'
  PYTHON_VERSION: '3.11'
  GO_VERSION: '1.21'

jobs:
  # üìã 1. Challenge Detection & Structure Validation
  detect-changes:
    name: üîç Detect Changed Challenges
    runs-on: ubuntu-latest
    outputs:
      challenges: ${{ steps.detect.outputs.challenges }}
      matrix: ${{ steps.detect.outputs.matrix }}
      has-changes: ${{ steps.detect.outputs.has-changes }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Detect Changed Challenges
        id: detect
        run: |
          set -e
          echo "üîç Detecting changed challenges..."
          
          # Finde alle Challenge-Ordner
          if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ -n "${{ github.event.inputs.challenge_path }}" ]; then
            CHANGED_CHALLENGES="${{ github.event.inputs.challenge_path }}"
          elif [ "${{ github.event_name }}" = "push" ]; then
            CHANGED_CHALLENGES=$(find challenges -mindepth 1 -maxdepth 1 -type d | head -10)
          else
            CHANGED_CHALLENGES=$(git diff --name-only ${{ github.event.pull_request.base.sha }} ${{ github.sha }} | grep '^challenges/' | cut -d'/' -f1-2 | sort -u)
          fi
          
          echo "Changed challenges: $CHANGED_CHALLENGES"
          
          if [ -z "$CHANGED_CHALLENGES" ]; then
            echo "has-changes=false" >> $GITHUB_OUTPUT
            echo "challenges=[]" >> $GITHUB_OUTPUT
            echo "matrix={\"include\":[]}" >> $GITHUB_OUTPUT
            echo "‚ÑπÔ∏è Keine Challenge-√Ñnderungen erkannt"
            exit 0
          fi
          
          echo "has-changes=true" >> $GITHUB_OUTPUT
          
          # JSON Array f√ºr Matrix aufbauen
          CHALLENGES_JSON="["
          MATRIX_JSON="{\"include\":["
          FIRST=true
          
          for challenge_dir in $CHANGED_CHALLENGES; do
            if [ -d "$challenge_dir" ] && [ -f "$challenge_dir/challenge.json" ]; then
              CHALLENGE_ID=$(basename "$challenge_dir")
              LANGUAGE=$(jq -r '.language' "$challenge_dir/challenge.json" 2>/dev/null || echo "unknown")
              DIFFICULTY=$(jq -r '.difficulty' "$challenge_dir/challenge.json" 2>/dev/null || echo "unknown")
              
              if [ "$FIRST" = true ]; then
                FIRST=false
              else
                CHALLENGES_JSON="$CHALLENGES_JSON,"
                MATRIX_JSON="$MATRIX_JSON,"
              fi
              
              CHALLENGES_JSON="$CHALLENGES_JSON\"$challenge_dir\""
              MATRIX_JSON="$MATRIX_JSON{\"path\":\"$challenge_dir\",\"id\":\"$CHALLENGE_ID\",\"language\":\"$LANGUAGE\",\"difficulty\":\"$DIFFICULTY\"}"
            fi
          done
          
          CHALLENGES_JSON="$CHALLENGES_JSON]"
          MATRIX_JSON="$MATRIX_JSON]}"
          
          echo "challenges=$CHALLENGES_JSON" >> $GITHUB_OUTPUT
          echo "matrix=$MATRIX_JSON" >> $GITHUB_OUTPUT
          
          echo "‚úÖ Detected challenges: $CHALLENGES_JSON"

  # üìã 2. Structure & Metadata Validation
  validate-structure:
    name: üìÅ Validate Structure
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.has-changes == 'true'
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.detect-changes.outputs.matrix) }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Validation Tools
        run: |
          sudo apt-get update
          sudo apt-get install -y jq python3-pip
          pip3 install jsonschema

      - name: Validate Challenge Structure
        run: |
          set -e
          CHALLENGE_PATH="${{ matrix.path }}"
          echo "üîç Validating structure for: $CHALLENGE_PATH"
          
          # 1. Grundlegende Datei-Existenz pr√ºfen
          echo "üìã Checking required files..."
          REQUIRED_FILES=("challenge.json" "README.md")
          LANGUAGE="${{ matrix.language }}"
          
          # Sprachspezifische Dateien hinzuf√ºgen
          case $LANGUAGE in
            "csharp")
              REQUIRED_FILES+=("starter.cs" "tests.cs")
              ;;
            "javascript")
              REQUIRED_FILES+=("starter.js" "tests.js")
              ;;
            "python")
              REQUIRED_FILES+=("starter.py" "tests.py")
              ;;
            "java")
              REQUIRED_FILES+=("starter.java" "tests.java")
              ;;
            "cpp")
              REQUIRED_FILES+=("starter.cpp" "tests.cpp")
              ;;
            "c")
              REQUIRED_FILES+=("starter.c" "tests.c")
              ;;
            "go")
              REQUIRED_FILES+=("starter.go" "tests.go")
              ;;
            "rust")
              REQUIRED_FILES+=("starter.rs" "tests.rs")
              ;;
          esac
          
          for file_pattern in "${REQUIRED_FILES[@]}"; do
            if [ ! -f "$CHALLENGE_PATH/$file_pattern" ]; then
              echo "‚ùå Required file missing: $file_pattern"
              exit 1
            fi
            echo "‚úÖ Found: $file_pattern"
          done

      - name: Validate challenge.json
        run: |
          set -e
          CHALLENGE_PATH="${{ matrix.path }}"
          
          echo "üìã Validating challenge.json structure..."
          
          # JSON Syntax Check
          if ! python3 -m json.tool "$CHALLENGE_PATH/challenge.json" > /dev/null; then
            echo "‚ùå Invalid JSON syntax in challenge.json"
            exit 1
          fi
          
          # Basic schema validation
          python3 -c "
          import json, sys
          
          required_fields = ['title', 'description', 'difficulty', 'language', 'tags', 'author', 'createdAt', 'status']
          valid_difficulties = ['easy', 'medium', 'hard']
          valid_languages = ['csharp', 'javascript', 'python', 'java', 'cpp', 'c', 'go', 'rust', 'kotlin']
          
          try:
              with open('$CHALLENGE_PATH/challenge.json', 'r') as f:
                  data = json.load(f)
              
              # Check required fields
              for field in required_fields:
                  if field not in data:
                      print(f'‚ùå Missing required field: {field}')
                      sys.exit(1)
              
              # Validate difficulty
              if data['difficulty'] not in valid_difficulties:
                  print(f'‚ùå Invalid difficulty: {data[\"difficulty\"]}')
                  sys.exit(1)
              
              # Validate language
              if data['language'] not in valid_languages:
                  print(f'‚ùå Invalid language: {data[\"language\"]}')
                  sys.exit(1)
              
              # Check title length
              if len(data['title']) < 3 or len(data['title']) > 100:
                  print(f'‚ùå Title length invalid: {len(data[\"title\"])} chars')
                  sys.exit(1)
              
              # Check description length
              if len(data['description']) < 20:
                  print(f'‚ùå Description too short: {len(data[\"description\"])} chars')
                  sys.exit(1)
              
              print('‚úÖ challenge.json is valid')
              
          except Exception as e:
              print(f'‚ùå Error validating challenge.json: {e}')
              sys.exit(1)
          "

      - name: Validate README.md
        run: |
          set -e
          CHALLENGE_PATH="${{ matrix.path }}"
          
          echo "üìã Validating README.md..."
          
          README_CONTENT=$(cat "$CHALLENGE_PATH/README.md")
          
          # Check required sections
          REQUIRED_SECTIONS=("# " "## üìù Beschreibung" "## üéØ Schwierigkeit" "## üíª Sprache" "## üöÄ Anweisungen")
          
          for section in "${REQUIRED_SECTIONS[@]}"; do
            if [[ ! "$README_CONTENT" == *"$section"* ]]; then
              echo "‚ùå Missing required section in README.md: $section"
              exit 1
            fi
          done
          
          echo "‚úÖ README.md structure is valid"

  # üß™ 3. Code Compilation & Syntax Tests
  test-compilation:
    name: üî® Test Compilation
    runs-on: ubuntu-latest
    needs: [detect-changes, validate-structure]
    if: needs.detect-changes.outputs.has-changes == 'true'
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.detect-changes.outputs.matrix) }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup .NET
        if: matrix.language == 'csharp'
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: Setup Node.js
        if: matrix.language == 'javascript'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup Python
        if: matrix.language == 'python'
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Setup Java
        if: matrix.language == 'java'
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '17'

      - name: Setup Go
        if: matrix.language == 'go'
        uses: actions/setup-go@v4
        with:
          go-version: ${{ env.GO_VERSION }}

      - name: Setup Rust
        if: matrix.language == 'rust'
        uses: dtolnay/rust-toolchain@stable

      - name: Install C/C++ Tools
        if: matrix.language == 'cpp' || matrix.language == 'c'
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential gcc g++ make

      - name: Test Compilation
        run: |
          set -e
          CHALLENGE_PATH="${{ matrix.path }}"
          LANGUAGE="${{ matrix.language }}"
          
          echo "üî® Testing compilation for $LANGUAGE challenge: $CHALLENGE_PATH"
          cd "$CHALLENGE_PATH"
          
          case $LANGUAGE in
            "csharp")
              echo "üî® Building C# project..."
              if ls *.csproj 1> /dev/null 2>&1; then
                dotnet build --configuration Release --verbosity minimal
                echo "‚úÖ C# compilation successful"
              else
                echo "‚ùå No .csproj file found"
                exit 1
              fi
              ;;
              
            "cpp")
              echo "üî® Building C++ project..."
              if [ -f "Makefile" ]; then
                make clean && make
                echo "‚úÖ C++ compilation successful"
              else
                g++ -std=c++17 -Wall -Wextra -O2 -o test_runner tests.cpp starter.cpp
                echo "‚úÖ C++ compilation successful (fallback)"
              fi
              ;;
              
            "c")
              echo "üî® Building C project..."
              if [ -f "Makefile" ]; then
                make clean && make
                echo "‚úÖ C compilation successful"
              else
                gcc -std=c99 -Wall -Wextra -O2 -o test_runner tests.c starter.c
                echo "‚úÖ C compilation successful (fallback)"
              fi
              ;;
              
            "javascript")
              echo "üî® Validating JavaScript syntax..."
              node -c starter.js
              node -c tests.js
              echo "‚úÖ JavaScript syntax valid"
              ;;
              
            "python")
              echo "üî® Validating Python syntax..."
              python -m py_compile starter.py
              python -m py_compile tests.py
              echo "‚úÖ Python syntax valid"
              ;;
              
            "java")
              echo "üî® Building Java project..."
              javac *.java
              echo "‚úÖ Java compilation successful"
              ;;
              
            "go")
              echo "üî® Building Go project..."
              if [ -f "go.mod" ]; then
                go mod tidy
              fi
              go build -v ./...
              echo "‚úÖ Go compilation successful"
              ;;
              
            "rust")
              echo "üî® Building Rust project..."
              cargo check
              cargo build
              echo "‚úÖ Rust compilation successful"
              ;;
              
            *)
              echo "‚ö†Ô∏è Compilation test not implemented for language: $LANGUAGE"
              ;;
          esac

  # üß™ 4. Test Framework Validation
  test-framework:
    name: üß™ Validate Test Framework
    runs-on: ubuntu-latest
    needs: [detect-changes, test-compilation]
    if: needs.detect-changes.outputs.has-changes == 'true'
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.detect-changes.outputs.matrix) }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Environment
        run: |
          # Setup based on language
          case "${{ matrix.language }}" in
            "csharp")
              wget https://dot.net/v1/dotnet-install.sh -O dotnet-install.sh
              chmod +x dotnet-install.sh
              ./dotnet-install.sh --channel 8.0
              export PATH="$HOME/.dotnet:$PATH"
              ;;
            "javascript")
              curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
              sudo apt-get install -y nodejs
              ;;
            "python")
              sudo apt-get update
              sudo apt-get install -y python3 python3-pip
              ;;
            "cpp"|"c")
              sudo apt-get update
              sudo apt-get install -y build-essential gcc g++ make
              ;;
            "java")
              sudo apt-get update
              sudo apt-get install -y openjdk-17-jdk
              ;;
          esac

      - name: Test Framework Validation
        run: |
          set -e
          CHALLENGE_PATH="${{ matrix.path }}"
          LANGUAGE="${{ matrix.language }}"
          
          echo "üß™ Testing framework for $LANGUAGE challenge: $CHALLENGE_PATH"
          cd "$CHALLENGE_PATH"
          
          # Determine starter file
          case $LANGUAGE in
            "csharp") STARTER_FILE="starter.cs" ;;
            "cpp") STARTER_FILE="starter.cpp" ;;
            "c") STARTER_FILE="starter.c" ;;
            "javascript") STARTER_FILE="starter.js" ;;
            "python") STARTER_FILE="starter.py" ;;
            "java") STARTER_FILE="starter.java" ;;
            "go") STARTER_FILE="starter.go" ;;
            "rust") STARTER_FILE="starter.rs" ;;
            *) echo "‚ö†Ô∏è Unknown language: $LANGUAGE"; exit 0 ;;
          esac
          
          if [ ! -f "$STARTER_FILE" ]; then
            echo "‚ùå Starter file not found: $STARTER_FILE"
            exit 1
          fi
          
          # Create backup
          cp "$STARTER_FILE" "${STARTER_FILE}.backup"
          
          # Test 1: Check if tests fail with incomplete starter code
          echo "üß™ Test 1: Verifying tests fail with incomplete starter code..."
          
          case $LANGUAGE in
            "csharp")
              export PATH="$HOME/.dotnet:$PATH"
              timeout 30s dotnet run > test_output.txt 2>&1 || TEST_EXIT_CODE=$?
              if [ "${TEST_EXIT_CODE:-0}" -eq 0 ] && grep -q "üéâ.*Tests bestanden" test_output.txt; then
                echo "‚ùå Tests should fail with incomplete starter code"
                cat test_output.txt
                exit 1
              fi
              ;;
            "cpp"|"c")
              if [ -f "test_runner" ] || [ -f "Makefile" ]; then
                [ -f "test_runner" ] || make > /dev/null 2>&1
                timeout 30s ./test_runner > test_output.txt 2>&1 || TEST_EXIT_CODE=$?
                if [ "${TEST_EXIT_CODE:-0}" -eq 0 ] && grep -q "üéâ.*Tests bestanden" test_output.txt; then
                  echo "‚ùå Tests should fail with incomplete starter code"
                  exit 1
                fi
              fi
              ;;
            "javascript")
              timeout 30s node tests.js > test_output.txt 2>&1 || TEST_EXIT_CODE=$?
              if [ "${TEST_EXIT_CODE:-0}" -eq 0 ] && grep -q "Tests bestanden" test_output.txt; then
                echo "‚ùå Tests should fail with incomplete starter code"
                exit 1
              fi
              ;;
            "python")
              timeout 30s python3 tests.py > test_output.txt 2>&1 || TEST_EXIT_CODE=$?
              if [ "${TEST_EXIT_CODE:-0}" -eq 0 ] && grep -q "Tests bestanden" test_output.txt; then
                echo "‚ùå Tests should fail with incomplete starter code"
                exit 1
              fi
              ;;
          esac
          
          echo "‚úÖ Tests correctly fail with incomplete starter code"
          
          # Restore original starter file
          mv "${STARTER_FILE}.backup" "$STARTER_FILE"
          
          echo "‚úÖ Test framework validation completed successfully"

  # üìä 5. Generate Validation Report
  generate-report:
    name: üìä Generate Validation Report
    runs-on: ubuntu-latest
    needs: [
      detect-changes,
      validate-structure,
      test-compilation,
      test-framework
    ]
    if: always() && needs.detect-changes.outputs.has-changes == 'true'
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Generate Validation Report
        run: |
          set -e
          
          echo "üìä Generating comprehensive validation report..."
          
          # Create report directory
          mkdir -p validation-reports
          REPORT_FILE="validation-reports/challenge-validation-$(date +%Y%m%d-%H%M%S).md"
          
          # Generate report header
          echo "# üéØ Challenge Validation Report" > "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          echo "**Generated:** $(date)" >> "$REPORT_FILE"
          echo "**Workflow:** ${{ github.workflow }}" >> "$REPORT_FILE"
          echo "**Run ID:** ${{ github.run_id }}" >> "$REPORT_FILE"
          echo "**Event:** ${{ github.event_name }}" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          echo "## üìã Summary" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          echo "| Challenge | Language | Difficulty | Status |" >> "$REPORT_FILE"
          echo "|-----------|----------|------------|--------|" >> "$REPORT_FILE"
          
          # Add challenge summary
          CHALLENGES='${{ needs.detect-changes.outputs.challenges }}'
          echo "$CHALLENGES" | jq -r '.[]' | while read -r challenge_path; do
            if [ -f "$challenge_path/challenge.json" ]; then
              TITLE=$(jq -r '.title' "$challenge_path/challenge.json")
              LANGUAGE=$(jq -r '.language' "$challenge_path/challenge.json")
              DIFFICULTY=$(jq -r '.difficulty' "$challenge_path/challenge.json")
              
              # Determine overall status based on job results
              OVERALL_STATUS="‚úÖ PASSED"
              if [ "${{ needs.validate-structure.result }}" != "success" ] || \
                 [ "${{ needs.test-compilation.result }}" != "success" ] || \
                 [ "${{ needs.test-framework.result }}" != "success" ]; then
                OVERALL_STATUS="‚ùå FAILED"
              fi
              
              echo "| $TITLE | $LANGUAGE | $DIFFICULTY | $OVERALL_STATUS |" >> "$REPORT_FILE"
            fi
          done
          
          # Add detailed results section
          echo "" >> "$REPORT_FILE"
          echo "## üîç Detailed Results" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          echo "### Structure Validation" >> "$REPORT_FILE"
          echo "**Status:** ${{ needs.validate-structure.result }}" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          echo "### Compilation Tests" >> "$REPORT_FILE"
          echo "**Status:** ${{ needs.test-compilation.result }}" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          echo "### Test Framework Validation" >> "$REPORT_FILE"
          echo "**Status:** ${{ needs.test-framework.result }}" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          
          # Add footer
          echo "" >> "$REPORT_FILE"
          echo "---" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          echo "**Generated by GitHub Actions** | [View Workflow](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> "$REPORT_FILE"
          
          echo "üìä Validation report generated: $REPORT_FILE"
          
          # Display report summary
          echo "## üìã Validation Summary"
          tail -n 20 "$REPORT_FILE"

      - name: Upload Validation Report
        uses: actions/upload-artifact@v4
        with:
          name: validation-report-${{ github.run_id }}
          path: validation-reports/
          retention-days: 30

  # ‚úÖ 6. Final Status Check
  validation-status:
    name: ‚úÖ Validation Status
    runs-on: ubuntu-latest
    needs: [
      detect-changes,
      validate-structure,
      test-compilation,
      test-framework,
      generate-report
    ]
    if: always()
    steps:
      - name: Determine Final Status
        run: |
          set -e
          
          echo "‚úÖ Determining final validation status..."
          
          # Check if any changes were detected
          if [ "${{ needs.detect-changes.outputs.has-changes }}" != "true" ]; then
            echo "‚ÑπÔ∏è No challenge changes detected - validation skipped"
            exit 0
          fi
          
          # Critical failures (should block merge)
          CRITICAL_FAILURES=()
          
          if [ "${{ needs.validate-structure.result }}" != "success" ]; then
            CRITICAL_FAILURES+=("Structure Validation")
          fi
          
          if [ "${{ needs.test-compilation.result }}" != "success" ]; then
            CRITICAL_FAILURES+=("Compilation Tests")
          fi
          
          if [ "${{ needs.test-framework.result }}" != "success" ]; then
            CRITICAL_FAILURES+=("Test Framework")
          fi
          
          # Report results
          if [ ${#CRITICAL_FAILURES[@]} -gt 0 ]; then
            echo "‚ùå CRITICAL FAILURES DETECTED:"
            printf '  - %s\n' "${CRITICAL_FAILURES[@]}"
            echo ""
            echo "üö´ Merge should be BLOCKED until these issues are resolved."
            exit 1
          else
            echo "üéâ ALL VALIDATIONS PASSED!"
            echo "‚úÖ Challenge(s) ready for merge."
            exit 0
          fi
