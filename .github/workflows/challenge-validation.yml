name: üéØ Challenge Validation

on:
  pull_request:
    branches: [ main, develop ]
    paths: 
      - 'challenges/**'
  push:
    branches: [ main ]
    paths:
      - 'challenges/**'
  workflow_dispatch:

env:
  NODE_VERSION: '18'
  DOTNET_VERSION: '8.0.x'
  PYTHON_VERSION: '3.11'

jobs:
  detect-changes:
    name: üîç Detect Changed Challenges
    runs-on: ubuntu-latest
    outputs:
      challenges: ${{ steps.detect.outputs.challenges }}
      has-changes: ${{ steps.detect.outputs.has-changes }}
      challenge-count: ${{ steps.detect.outputs.challenge-count }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Detect Changed Challenges
        id: detect
        run: |
          set -e
          echo "üîç Detecting changed challenges..."
          
          # Find changed challenges based on event type
          if [ "${{ github.event_name }}" = "push" ]; then
            CHANGED_CHALLENGES=$(find challenges -mindepth 1 -maxdepth 1 -type d -name "*" | head -10)
          elif [ "${{ github.event_name }}" = "pull_request" ]; then
            CHANGED_CHALLENGES=$(git diff --name-only ${{ github.event.pull_request.base.sha }} ${{ github.sha }} | grep '^challenges/' | cut -d'/' -f1-2 | sort -u)
          else
            CHANGED_CHALLENGES=$(find challenges -mindepth 1 -maxdepth 1 -type d -name "*" | head -5)
          fi
          
          echo "Raw changed challenges: $CHANGED_CHALLENGES"
          
          # Filter out only valid challenge directories
          VALID_CHALLENGES=""
          CHALLENGE_COUNT=0
          
          for challenge_dir in $CHANGED_CHALLENGES; do
            if [ -d "$challenge_dir" ] && [ -f "$challenge_dir/challenge.json" ]; then
              echo "‚úÖ Valid challenge found: $challenge_dir"
              if [ -z "$VALID_CHALLENGES" ]; then
                VALID_CHALLENGES="$challenge_dir"
              else
                VALID_CHALLENGES="$VALID_CHALLENGES $challenge_dir"
              fi
              CHALLENGE_COUNT=$((CHALLENGE_COUNT + 1))
            else
              echo "‚ö†Ô∏è Skipping invalid challenge directory: $challenge_dir"
            fi
          done
          
          echo "Valid challenges: $VALID_CHALLENGES"
          echo "Challenge count: $CHALLENGE_COUNT"
          
          if [ -z "$VALID_CHALLENGES" ]; then
            echo "has-changes=false" >> $GITHUB_OUTPUT
            echo "challenges=" >> $GITHUB_OUTPUT
            echo "challenge-count=0" >> $GITHUB_OUTPUT
            echo "‚ÑπÔ∏è No valid challenge changes detected"
          else
            echo "has-changes=true" >> $GITHUB_OUTPUT
            echo "challenges=$VALID_CHALLENGES" >> $GITHUB_OUTPUT
            echo "challenge-count=$CHALLENGE_COUNT" >> $GITHUB_OUTPUT
            echo "‚úÖ Detected $CHALLENGE_COUNT valid challenge(s): $VALID_CHALLENGES"
          fi

  validate-structure:
    name: üìÅ Validate Structure
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.has-changes == 'true'
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Tools
        run: |
          sudo apt-get update
          sudo apt-get install -y jq python3-pip
          pip3 install jsonschema

      - name: Validate Challenge Structure
        run: |
          set -e
          
          CHALLENGES="${{ needs.detect-changes.outputs.challenges }}"
          echo "üîç Validating challenges: $CHALLENGES"
          
          if [ -z "$CHALLENGES" ]; then
            echo "‚ÑπÔ∏è No challenges to validate"
            exit 0
          fi
          
          for challenge_path in $CHALLENGES; do
            if [ -d "$challenge_path" ]; then
              echo "üîç Validating structure for: $challenge_path"
              
              # Check basic files exist
              if [ ! -f "$challenge_path/challenge.json" ]; then
                echo "‚ùå Missing challenge.json in $challenge_path"
                exit 1
              fi
              
              if [ ! -f "$challenge_path/README.md" ]; then
                echo "‚ùå Missing README.md in $challenge_path"
                exit 1
              fi
              
              # Validate JSON syntax
              if ! jq empty "$challenge_path/challenge.json" 2>/dev/null; then
                echo "‚ùå Invalid JSON syntax in $challenge_path/challenge.json"
                exit 1
              fi
              
              # Get language from challenge.json
              LANGUAGE=$(jq -r '.language // "unknown"' "$challenge_path/challenge.json" 2>/dev/null)
              echo "üìã Language detected: $LANGUAGE"
              
              # Check language-specific starter and test files
              case $LANGUAGE in
                "csharp")
                  if [ ! -f "$challenge_path/starter.cs" ]; then
                    echo "‚ùå Missing starter.cs in $challenge_path"
                    exit 1
                  fi
                  if [ ! -f "$challenge_path/tests.cs" ]; then
                    echo "‚ùå Missing tests.cs in $challenge_path"
                    exit 1
                  fi
                  echo "‚úÖ C# files found"
                  ;;
                "javascript")
                  if [ ! -f "$challenge_path/starter.js" ]; then
                    echo "‚ùå Missing starter.js in $challenge_path"
                    exit 1
                  fi
                  if [ ! -f "$challenge_path/tests.js" ]; then
                    echo "‚ùå Missing tests.js in $challenge_path"
                    exit 1
                  fi
                  echo "‚úÖ JavaScript files found"
                  ;;
                "python")
                  if [ ! -f "$challenge_path/starter.py" ]; then
                    echo "‚ùå Missing starter.py in $challenge_path"
                    exit 1
                  fi
                  if [ ! -f "$challenge_path/tests.py" ]; then
                    echo "‚ùå Missing tests.py in $challenge_path"
                    exit 1
                  fi
                  echo "‚úÖ Python files found"
                  ;;
                "cpp")
                  if [ ! -f "$challenge_path/starter.cpp" ]; then
                    echo "‚ùå Missing starter.cpp in $challenge_path"
                    exit 1
                  fi
                  if [ ! -f "$challenge_path/tests.cpp" ]; then
                    echo "‚ùå Missing tests.cpp in $challenge_path"
                    exit 1
                  fi
                  echo "‚úÖ C++ files found"
                  ;;
                "c")
                  if [ ! -f "$challenge_path/starter.c" ]; then
                    echo "‚ùå Missing starter.c in $challenge_path"
                    exit 1
                  fi
                  if [ ! -f "$challenge_path/tests.c" ]; then
                    echo "‚ùå Missing tests.c in $challenge_path"
                    exit 1
                  fi
                  echo "‚úÖ C files found"
                  ;;
                "java")
                  if [ ! -f "$challenge_path/starter.java" ]; then
                    echo "‚ùå Missing starter.java in $challenge_path"
                    exit 1
                  fi
                  if [ ! -f "$challenge_path/tests.java" ]; then
                    echo "‚ùå Missing tests.java in $challenge_path"
                    exit 1
                  fi
                  echo "‚úÖ Java files found"
                  ;;
                *)
                  echo "‚ö†Ô∏è Unknown language: $LANGUAGE, skipping language-specific validation"
                  ;;
              esac
              
              echo "‚úÖ Structure validation passed for $challenge_path"
            else
              echo "‚ö†Ô∏è Challenge directory not found: $challenge_path"
            fi
          done
          
          echo "üéâ All structure validations completed successfully"

  validate-metadata:
    name: üè∑Ô∏è Validate Metadata
    runs-on: ubuntu-latest
    needs: detect-changes
    if: needs.detect-changes.outputs.has-changes == 'true'
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Validate Challenge Metadata
        run: |
          set -e
          
          CHALLENGES="${{ needs.detect-changes.outputs.challenges }}"
          echo "üè∑Ô∏è Validating metadata for challenges: $CHALLENGES"
          
          if [ -z "$CHALLENGES" ]; then
            echo "‚ÑπÔ∏è No challenges to validate"
            exit 0
          fi
          
          for challenge_path in $CHALLENGES; do
            if [ -f "$challenge_path/challenge.json" ]; then
              echo "üè∑Ô∏è Validating metadata for: $challenge_path"
              
              # Use Python for robust JSON validation
              python3 << EOF
import json
import sys
import os
from datetime import datetime

required_fields = ['title', 'description', 'difficulty', 'language', 'tags', 'author', 'createdAt', 'status']
valid_difficulties = ['easy', 'medium', 'hard']
valid_languages = ['csharp', 'javascript', 'python', 'java', 'cpp', 'c', 'go', 'rust']

try:
    with open('$challenge_path/challenge.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"üìã Challenge: {data.get('title', 'Unknown')}")
    
    # Check required fields
    missing_fields = []
    for field in required_fields:
        if field not in data:
            missing_fields.append(field)
    
    if missing_fields:
        print(f"‚ùå Missing required fields: {', '.join(missing_fields)}")
        sys.exit(1)
    
    # Validate difficulty
    if data['difficulty'] not in valid_difficulties:
        print(f"‚ùå Invalid difficulty: {data['difficulty']}. Must be one of: {', '.join(valid_difficulties)}")
        sys.exit(1)
    
    # Validate language
    if data['language'] not in valid_languages:
        print(f"‚ùå Invalid language: {data['language']}. Must be one of: {', '.join(valid_languages)}")
        sys.exit(1)
    
    # Check title length
    if len(data['title']) < 3 or len(data['title']) > 100:
        print(f"‚ùå Title length invalid: {len(data['title'])} chars (must be 3-100)")
        sys.exit(1)
    
    # Check description length
    if len(data['description']) < 20:
        print(f"‚ùå Description too short: {len(data['description'])} chars (minimum 20)")
        sys.exit(1)
    
    # Check tags
    if not isinstance(data['tags'], list) or len(data['tags']) == 0:
        print("‚ùå Tags must be a non-empty array")
        sys.exit(1)
    
    # Check status
    if data['status'] not in ['pending', 'approved', 'rejected']:
        print(f"‚ùå Invalid status: {data['status']}")
        sys.exit(1)
    
    print(f"‚úÖ Metadata validation passed for: {data['title']}")
    
except FileNotFoundError:
    print(f"‚ùå File not found: $challenge_path/challenge.json")
    sys.exit(1)
except json.JSONDecodeError as e:
    print(f"‚ùå JSON decode error: {e}")
    sys.exit(1)
except Exception as e:
    print(f"‚ùå Validation error: {e}")
    sys.exit(1)
EOF
              
              if [ $? -ne 0 ]; then
                echo "‚ùå Metadata validation failed for $challenge_path"
                exit 1
              fi
            else
              echo "‚ö†Ô∏è challenge.json not found in $challenge_path"
            fi
          done
          
          echo "üéâ All metadata validations completed successfully"

  test-compilation:
    name: üî® Test Compilation
    runs-on: ubuntu-latest
    needs: [detect-changes, validate-structure]
    if: needs.detect-changes.outputs.has-changes == 'true'
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: ${{ env.DOTNET_VERSION }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '17'

      - name: Install Build Tools
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential gcc g++ make jq

      - name: Test Compilation
        run: |
          set -e
          
          CHALLENGES="${{ needs.detect-changes.outputs.challenges }}"
          echo "üî® Testing compilation for challenges: $CHALLENGES"
          
          if [ -z "$CHALLENGES" ]; then
            echo "‚ÑπÔ∏è No challenges to test"
            exit 0
          fi
          
          for challenge_path in $CHALLENGES; do
            if [ -d "$challenge_path" ]; then
              echo "üî® Testing compilation for: $challenge_path"
              cd "$challenge_path"
              
              # Get language from challenge.json
              LANGUAGE=$(jq -r '.language // "unknown"' "challenge.json" 2>/dev/null)
              echo "üìã Testing $LANGUAGE compilation..."
              
              case $LANGUAGE in
                "csharp")
                  if ls *.csproj 1> /dev/null 2>&1; then
                    echo "üî® Building C# project..."
                    dotnet build --configuration Release --verbosity minimal --nologo
                    echo "‚úÖ C# compilation successful"
                  else
                    echo "‚ö†Ô∏è No .csproj file found, skipping C# build"
                  fi
                  ;;
                  
                "javascript")
                  echo "üî® Validating JavaScript syntax..."
                  if [ -f "starter.js" ]; then
                    node -c starter.js
                    echo "‚úÖ starter.js syntax valid"
                  fi
                  if [ -f "tests.js" ]; then
                    node -c tests.js
                    echo "‚úÖ tests.js syntax valid"
                  fi
                  echo "‚úÖ JavaScript validation successful"
                  ;;
                  
                "python")
                  echo "üî® Validating Python syntax..."
                  if [ -f "starter.py" ]; then
                    python3 -m py_compile starter.py
                    echo "‚úÖ starter.py syntax valid"
                  fi
                  if [ -f "tests.py" ]; then
                    python3 -m py_compile tests.py
                    echo "‚úÖ tests.py syntax valid"
                  fi
                  echo "‚úÖ Python validation successful"
                  ;;
                  
                "cpp")
                  echo "üî® Building C++ project..."
                  if [ -f "Makefile" ]; then
                    make clean && make
                  else
                    g++ -std=c++17 -Wall -Wextra -O2 -c starter.cpp -o starter.o
                    g++ -std=c++17 -Wall -Wextra -O2 -c tests.cpp -o tests.o
                    rm -f *.o
                  fi
                  echo "‚úÖ C++ compilation successful"
                  ;;
                  
                "c")
                  echo "üî® Building C project..."
                  if [ -f "Makefile" ]; then
                    make clean && make
                  else
                    gcc -std=c99 -Wall -Wextra -O2 -c starter.c -o starter.o
                    gcc -std=c99 -Wall -Wextra -O2 -c tests.c -o tests.o
                    rm -f *.o
                  fi
                  echo "‚úÖ C compilation successful"
                  ;;
                  
                "java")
                  echo "üî® Building Java project..."
                  javac *.java
                  rm -f *.class
                  echo "‚úÖ Java compilation successful"
                  ;;
                  
                *)
                  echo "‚ö†Ô∏è Compilation test not implemented for: $LANGUAGE"
                  ;;
              esac
              
              cd ..
            else
              echo "‚ö†Ô∏è Challenge directory not found: $challenge_path"
            fi
          done
          
          echo "üéâ All compilation tests completed successfully"

  test-framework:
    name: üß™ Test Framework
    runs-on: ubuntu-latest
    needs: [detect-changes, test-compilation]
    if: needs.detect-changes.outputs.has-changes == 'true'
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Environment
        run: |
          # .NET
          wget https://dot.net/v1/dotnet-install.sh -O dotnet-install.sh
          chmod +x dotnet-install.sh
          ./dotnet-install.sh --channel 8.0 --install-dir ~/.dotnet
          export PATH="$HOME/.dotnet:$PATH"
          echo "$HOME/.dotnet" >> $GITHUB_PATH
          
          # Node.js
          curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
          sudo apt-get install -y nodejs
          
          # Python and build tools
          sudo apt-get update
          sudo apt-get install -y python3 python3-pip build-essential gcc g++ make openjdk-17-jdk jq

      - name: Test Framework Validation
        run: |
          set -e
          
          CHALLENGES="${{ needs.detect-changes.outputs.challenges }}"
          echo "üß™ Testing framework for challenges: $CHALLENGES"
          
          if [ -z "$CHALLENGES" ]; then
            echo "‚ÑπÔ∏è No challenges to test"
            exit 0
          fi
          
          for challenge_path in $CHALLENGES; do
            if [ -d "$challenge_path" ]; then
              echo "üß™ Testing framework for: $challenge_path"
              cd "$challenge_path"
              
              # Get language from challenge.json
              LANGUAGE=$(jq -r '.language // "unknown"' "challenge.json" 2>/dev/null)
              echo "üìã Testing $LANGUAGE test framework..."
              
              # Basic framework test - check if tests can be executed
              case $LANGUAGE in
                "csharp")
                  if ls *.csproj 1> /dev/null 2>&1; then
                    echo "üß™ Testing C# framework..."
                    export PATH="$HOME/.dotnet:$PATH"
                    timeout 30s dotnet run > test_output.txt 2>&1 || TEST_EXIT_CODE=$?
                    if [ -f test_output.txt ]; then
                      echo "‚úÖ C# test framework is executable"
                      head -5 test_output.txt | grep -E "üß™|Test|Error" || true
                    fi
                  fi
                  ;;
                  
                "javascript")
                  if [ -f "tests.js" ]; then
                    echo "üß™ Testing JavaScript framework..."
                    timeout 30s node tests.js > test_output.txt 2>&1 || TEST_EXIT_CODE=$?
                    if [ -f test_output.txt ]; then
                      echo "‚úÖ JavaScript test framework is executable"
                      head -5 test_output.txt | grep -E "Test|Error" || true
                    fi
                  fi
                  ;;
                  
                "python")
                  if [ -f "tests.py" ]; then
                    echo "üß™ Testing Python framework..."
                    timeout 30s python3 tests.py > test_output.txt 2>&1 || TEST_EXIT_CODE=$?
                    if [ -f test_output.txt ]; then
                      echo "‚úÖ Python test framework is executable"
                      head -5 test_output.txt | grep -E "Test|Error" || true
                    fi
                  fi
                  ;;
                  
                "cpp")
                  if [ -f "Makefile" ]; then
                    echo "üß™ Testing C++ framework..."
                    make clean > /dev/null 2>&1 || true
                    make > /dev/null 2>&1 || true
                    if [ -f "test_runner" ]; then
                      timeout 30s ./test_runner > test_output.txt 2>&1 || TEST_EXIT_CODE=$?
                      echo "‚úÖ C++ test framework is executable"
                      if [ -f test_output.txt ]; then
                        head -5 test_output.txt | grep -E "Test|Error" || true
                      fi
                    fi
                  fi
                  ;;
                  
                "c")
                  if [ -f "Makefile" ]; then
                    echo "üß™ Testing C framework..."
                    make clean > /dev/null 2>&1 || true
                    make > /dev/null 2>&1 || true
                    if [ -f "test_runner" ]; then
                      timeout 30s ./test_runner > test_output.txt 2>&1 || TEST_EXIT_CODE=$?
                      echo "‚úÖ C test framework is executable"
                      if [ -f test_output.txt ]; then
                        head -5 test_output.txt | grep -E "Test|Error" || true
                      fi
                    fi
                  fi
                  ;;
                  
                "java")
                  if [ -f "tests.java" ]; then
                    echo "üß™ Testing Java framework..."
                    javac *.java > /dev/null 2>&1 || true
                    if [ -f "Tests.class" ]; then
                      timeout 30s java Tests > test_output.txt 2>&1 || TEST_EXIT_CODE=$?
                      echo "‚úÖ Java test framework is executable"
                      if [ -f test_output.txt ]; then
                        head -5 test_output.txt | grep -E "Test|Error" || true
                      fi
                    fi
                  fi
                  ;;
                  
                *)
                  echo "‚ö†Ô∏è Framework test not implemented for: $LANGUAGE"
                  ;;
              esac
              
              # Cleanup test files
              rm -f test_output.txt *.o *.class test_runner
              
              cd ..
            else
              echo "‚ö†Ô∏è Challenge directory not found: $challenge_path"
            fi
          done
          
          echo "üéâ All framework tests completed successfully"

  generate-report:
    name: üìä Generate Report
    runs-on: ubuntu-latest
    needs: [detect-changes, validate-structure, validate-metadata, test-compilation, test-framework]
    if: always() && needs.detect-changes.outputs.has-changes == 'true'
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Generate Validation Report
        run: |
          set -e
          
          echo "üìä Generating validation report..."
          
          mkdir -p validation-reports
          REPORT_FILE="validation-reports/challenge-validation-$(date +%Y%m%d-%H%M%S).md"
          
          # Create report header
          echo "# üéØ Challenge Validation Report" > "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          echo "**Generated:** $(date)" >> "$REPORT_FILE"
          echo "**Workflow:** ${{ github.workflow }}" >> "$REPORT_FILE"
          echo "**Run ID:** ${{ github.run_id }}" >> "$REPORT_FILE"
          echo "**Event:** ${{ github.event_name }}" >> "$REPORT_FILE"
          echo "**Challenges Detected:** ${{ needs.detect-changes.outputs.challenge-count }}" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          
          # Job status summary
          echo "## üìã Job Status Summary" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          echo "| Job | Status |" >> "$REPORT_FILE"
          echo "|-----|--------|" >> "$REPORT_FILE"
          echo "| Structure Validation | ${{ needs.validate-structure.result }} |" >> "$REPORT_FILE"
          echo "| Metadata Validation | ${{ needs.validate-metadata.result }} |" >> "$REPORT_FILE"
          echo "| Compilation Tests | ${{ needs.test-compilation.result }} |" >> "$REPORT_FILE"
          echo "| Framework Tests | ${{ needs.test-framework.result }} |" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          
          # Challenge details
          echo "## üéØ Validated Challenges" >> "$REPORT_FILE"
          echo "" >> "$REPORT_FILE"
          
          CHALLENGES="${{ needs.detect-changes.outputs.challenges }}"
          if [ -n "$CHALLENGES" ]; then
            for challenge_path in $CHALLENGES; do
              if [ -f "$challenge_path/challenge.json" ]; then
                TITLE=$(jq -r '.title // "Unknown"' "$challenge_path/challenge.json" 2>/dev/null)
                LANGUAGE=$(jq -r '.language // "unknown"' "$challenge_path/challenge.json" 2>/dev/null)
                DIFFICULTY=$(jq -r '.difficulty // "unknown"' "$challenge_path/challenge.json" 2>/dev/null)
                echo "- ‚úÖ **$TITLE** ($LANGUAGE, $DIFFICULTY) - \`$challenge_path\`" >> "$REPORT_FILE"
              else
                echo "- ‚ö†Ô∏è **Unknown Challenge** - \`$challenge_path\` (no challenge.json)" >> "$REPORT_FILE"
              fi
            done
          else
            echo "No challenges were processed in this run." >> "$REPORT_FILE"
          fi
          
          echo "" >> "$REPORT_FILE"
          echo "---" >> "$REPORT_FILE"
          echo "**Generated by GitHub Actions** | [View Run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> "$REPORT_FILE"
          
          echo "üìä Report generated successfully"
          echo "Report content:"
          cat "$REPORT_FILE"

      - name: Upload Report
        uses: actions/upload-artifact@v4
        with:
          name: validation-report-${{ github.run_id }}
          path: validation-reports/
          retention-days: 30

      - name: Add Job Summary
        run: |
          # Add content to GitHub Actions job summary
          CHALLENGES="${{ needs.detect-changes.outputs.challenges }}"
          CHALLENGE_COUNT="${{ needs.detect-changes.outputs.challenge-count }}"
          
          echo "## üéØ Challenge Validation Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Challenges processed:** $CHALLENGE_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Structure Validation | ${{ needs.validate-structure.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Metadata Validation | ${{ needs.validate-metadata.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Compilation Tests | ${{ needs.test-compilation.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Framework Tests | ${{ needs.test-framework.result }} |" >> $GITHUB_STEP_SUMMARY

  validation-status:
    name: ‚úÖ Final Status
    runs-on: ubuntu-latest
    needs: [detect-changes, validate-structure, validate-metadata, test-compilation, test-framework]
    if: always()
    steps:
      - name: Determine Status
        run: |
          set -e
          
          echo "‚úÖ Determining final validation status..."
          
          # Check if changes were detected
          if [ "${{ needs.detect-changes.outputs.has-changes }}" != "true" ]; then
            echo "‚ÑπÔ∏è No challenge changes detected - validation skipped"
            echo "Status: SKIPPED - No changes to validate"
            exit 0
          fi
          
          echo "üìã Challenge count: ${{ needs.detect-changes.outputs.challenge-count }}"
          echo "üìã Challenges: ${{ needs.detect-changes.outputs.challenges }}"
          
          # Check critical job results
          FAILED_JOBS=()
          
          if [ "${{ needs.validate-structure.result }}" != "success" ]; then
            FAILED_JOBS+=("Structure Validation (${{ needs.validate-structure.result }})")
          fi
          
          if [ "${{ needs.validate-metadata.result }}" != "success" ]; then
            FAILED_JOBS+=("Metadata Validation (${{ needs.validate-metadata.result }})")
          fi
          
          if [ "${{ needs.test-compilation.result }}" != "success" ]; then
            FAILED_JOBS+=("Compilation Tests (${{ needs.test-compilation.result }})")
          fi
          
          if [ "${{ needs.test-framework.result }}" != "success" ]; then
            FAILED_JOBS+=("Framework Tests (${{ needs.test-framework.result }})")
          fi
          
          # Report final status
          if [ ${#FAILED_JOBS[@]} -gt 0 ]; then
            echo "‚ùå CRITICAL FAILURES DETECTED:"
            printf '  - %s\n' "${FAILED_JOBS[@]}"
            echo ""
            echo "üö´ Merge blocked until issues are resolved"
            echo "Status: FAILED - Critical validations failed"
            exit 1
          else
            echo "üéâ ALL VALIDATIONS PASSED!"
            echo "‚úÖ ${{ needs.detect-changes.outputs.challenge-count }} challenge(s) successfully validated"
            echo "‚úÖ Ready for merge"
            echo "Status: SUCCESS - All validations passed"
            exit 0
          fi
